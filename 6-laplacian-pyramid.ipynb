{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The Laplacian Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import warnings\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "from cued_sf2_lab.familiarisation import load_mat_img, plot_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 The basic concept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure id=\"figure-2\">\n",
    "<div style=\"background-color: white\">\n",
    "\n",
    "![](figures/laplacian.svg)</div>\n",
    "    \n",
    "<figcaption style=\"text-align: center\">Figure 2: A typical laplacian pyramid with 2 levels; forward (analysis) part only</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Laplacian pyramid is an energy compaction technique, based on\n",
    "the observation:\n",
    "\n",
    "> For most real-world images, the high-frequency energy is much less than the low-frequency energy.\n",
    "\n",
    "Since the lowpass image is much lower bandwidth than the\n",
    "original image, it can be subsampled (*decimated*) 2:1 in both\n",
    "horizontal and vertical directions, without significant loss of\n",
    "information to give a quarter-size lowpass image.  We have\n",
    "provided a row filter/decimation function, `rowdec(X, h)`, to\n",
    "filter and decimate the rows of a matrix by 2:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import rowdec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this twice\n",
    "(on the image and its transpose) to generate a quarter-size\n",
    "lowpass image `X1` of Lighthouse.  For simplicity use a 3-tap (length 3)\n",
    "filter `h` with coefficients: $\\frac{1}{4} [1\\ 2\\ 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, cmaps_dict = load_mat_img(img='lighthouse.mat', img_info='X', cmap_info={'map', 'map2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.25*np.array([1, 2, 1])\n",
    "# your code here\n",
    "print(X.shape[0])\n",
    "X_rd = rowdec(X, h)\n",
    "X1 = rowdec(X_rd.T, h).T  \n",
    "print(X1.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image `X1` can be interpolated 2:1 in each direction to\n",
    "generate a lowpass image of the original size, which can then be\n",
    "subtracted from the original to yield a full-size highpass image.\n",
    "We have also provided a row interpolation/filter function,\n",
    "`rowint(X, h)`, which doubles the length of each row of the image, by\n",
    "inserting zeros between alternate samples and then lowpass\n",
    "filtering the result with the filter `h`. Note that to undo the decimation\n",
    "performed by `Y = rowdec(X, h)`, this should be called as `Z = rowint(Y, 2*h)`,\n",
    "where a DC gain of 2 is added, as shown in [Figure 2](#figure-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import rowint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this twice (as before) to generate\n",
    "a full-size lowpass image, and subtract this from `X` to\n",
    "give a highpass image `Y0`. Display `X1` and `Y0` to see these effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "Z_rd = rowint(X1, 2*h)\n",
    "print(Z_rd.shape[0])\n",
    "Z = rowint(Z_rd.T, 2*h).T\n",
    "print(Z.shape[0])\n",
    "Y0 = X - Z\n",
    "fig, axs = plt.subplots(2, figsize = (10,10))\n",
    "plot_image(X1, ax=axs[0])\n",
    "axs[0].set(title='X1 - low pass image')\n",
    "plot_image(Y0, ax=axs[1])\n",
    "axs[1].set(title='Y0 - high pass image')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highpass images will\n",
    "always have approximately zero mean (since any dc component is\n",
    "removed). Hence for the remainder of this project, we recommend\n",
    "that you also make all lowpass images be approximately zero mean\n",
    "by subtracting 128 from them before you start any processing. This\n",
    "makes the 8-bit pixel values cover the range -128 to 127,\n",
    "instead of 0 to 255. The advantages of having a zero-mean input image are not very obvious here, but they\n",
    "will become clearer as the project progresses. If you use `draw_image` the images will still be displayed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, cmaps_dict = load_mat_img(img='lighthouse.mat', img_info='X', cmap_info={'map', 'map2'})\n",
    "X = X - 128.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the functions ```rowdec``` and ```rowint``` and check that you understand how they work. Decimation is achieved by selecting every second element of a vector using selection indices `i:i+c:2`, and filtering is performed with symmetric extension as in ```convse```, except that we do not bother to calculate the filter outputs that are to be discarded by the decimation process. Interpolation is achieved by loading every second element of a double-size vector using `X2 = np.zeros((r, c2), dtype=X.dtype)`, `X2[:, ::2] = X`. The intermediate samples of the interpolated vector x must be zero before the vector is passed through the interpolation filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Code(inspect.getsource(rowdec), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Code(inspect.getsource(rowint), language=\"python\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the small lowpass image `X1` and the full-size highpass image `Y0`\n",
    "are transmitted to a distant decoder, then the decoder can exactly reconstruct\n",
    "the original image by interpolating `X1` up to full size and adding in\n",
    "`Y0` (which represents the error between the original and the interpolated\n",
    "`X1`).  We have achieved image compression if `X1` and `Y0` can be\n",
    "transmitted with fewer bits than `X`.  Usually this will be the case\n",
    "because `Y0` contains so much less energy than `X`, and `X1` is\n",
    "only one quarter of the size of `X`.  However we do start at a\n",
    "disadvantage because there are 25% more samples to code.  Many of the `Y0` samples may be represented by zero, and we shall show later that runs of\n",
    "zeros may be coded with relatively few bits.\n",
    "\n",
    "The quarter-size lowpass image `X1` may be further subsampled, using the\n",
    "same process as was applied to `X`, so that it may be transmitted as a\n",
    "one-sixteenth-size lowpass image `X2` and a quarter-size highpass image\n",
    "`Y1`.  This usually achieves further data compression and may be repeated\n",
    "as many times as is desired (until, for typical images, no further compression\n",
    "is achieved).  This leads to a pyramid of highpass images and a final tiny\n",
    "lowpass image.  Usually three or four layers of the pyramid are sufficient to\n",
    "give maximum compression.\n",
    "\n",
    "Write a `py4enc(X, h)` function to generate a 4-layer pyramid, so that `X` is split into four\n",
    "highpass images, `Y0 Y1 Y2 Y3`, each a quarter of the size of its predecessor, plus a tiny\n",
    "lowpass image `X4`, which is a quarter of the size of `Y3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py4enc(X, h):\n",
    "    # YO\n",
    "    X_1rd = rowdec(X, h)\n",
    "    X_1rd2 = rowdec(X_1rd.T, h).T\n",
    "    X_1 = rowint(X_1rd2, 2*h)\n",
    "    X1 = rowint(X_1.T, 2*h).T\n",
    "    Y0 = X - X1\n",
    "\n",
    "    # Y1\n",
    "    X_2rd = rowdec(X1, h)\n",
    "    X_2rd2 = rowdec(X_2rd.T, h).T\n",
    "    X_2 = rowint(X_2rd2, 2*h)\n",
    "    X2 = rowint(X_2.T, 2*h).T\n",
    "    Y1 = X1 - X2\n",
    "\n",
    "    # Y2\n",
    "    X_3rd = rowdec(X2, h)\n",
    "    X_3rd2 = rowdec(X_3rd.T, h).T\n",
    "    X_3 = rowint(X_3rd2, 2*h)\n",
    "    X3 = rowint(X_3.T, 2*h).T\n",
    "    Y2 = X2 - X3\n",
    "\n",
    "    # Y3\n",
    "    X_4rd = rowdec(X3, h)\n",
    "    X_4rd2 = rowdec(X_4rd.T, h).T\n",
    "    X_4 = rowint(X_4rd2, 2*h)\n",
    "    X4 = rowint(X_4.T, 2*h).T\n",
    "    Y3 = X3 - X4\n",
    "\n",
    "    \n",
    "    \n",
    "    # remove these lines when implementing your code - they are here to show you what shape the plots below should be\n",
    "    Y0 = np.full(X.shape, np.nan)\n",
    "    Y1 = np.full(X.shape >> np.int_(1), np.nan)\n",
    "    Y2 = np.full(X.shape >> np.int_(2), np.nan)\n",
    "    Y3 = np.full(X.shape >> np.int_(3), np.nan)\n",
    "    X4 = np.full(X.shape >> np.int_(4), np.nan)\n",
    "\n",
    "    return Y0, Y1, Y2, Y3, X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4enc(X,h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the results to check them using the `beside` helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import beside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0, Y1, Y2, Y3, X4 = py4enc(X, h)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "plot_image(beside(Y0, beside(Y1, beside(Y2, beside(Y3, X4)))), ax=ax);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to see the images separately from each other, instead of using our `beside` function that was written to match the old Matlab version, we can draw this directly with `matplotlib` using [`plt.subplots`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html) to create a set of subplots, and the `width_ratios` argument to [`GridSpec`](https://matplotlib.org/stable/api/_as_gen/matplotlib.gridspec.GridSpec.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Y_0\", \"Y_1\", \"Y_2\", \"Y_3\", \"X_4\"]\n",
    "imgs = [Y0, Y1, Y2, Y3, X4]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(8, 4),\n",
    "                        gridspec_kw=dict(width_ratios=[img.shape[0] for img in imgs]))\n",
    "\n",
    "for ax, img, title in zip(axs, imgs, titles):\n",
    "    plot_image(img, ax=ax)\n",
    "    ax.set(yticks=[], title=f'${title}$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to see the images at the same scale as each other, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Y_0\", \"Y_1\", \"Y_2\", \"Y_3\", \"X_4\"]\n",
    "imgs = [Y0, Y1, Y2, Y3, X4]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(8, 2))\n",
    "\n",
    "for ax, img, title in zip(axs, imgs, titles):\n",
    "    plot_image(img, ax=ax)\n",
    "    ax.set(yticks=[], title=f'${title}$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a demonstrator to check that your images look correct, and\n",
    "then write another function `py4dec` to decode `X4` and\n",
    "`Y3 Y2 Y1 Y0` into a set of lowpass images `Z3 Z2 Z1 Z0`.\n",
    "(`Z3` is obtained by interpolating `X4` and adding\n",
    "`Y3`, and then `Z2` is obtained from `Z3` and `Y2`, and\n",
    "so on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py4dec(Y0, Y1, Y2, Y3, X4, h):\n",
    "    # your code here\n",
    "    warnings.warn(\"you need to write this!\")\n",
    "\n",
    "    # remove these lines when implementing your code - they are here to show you what shape the plots below should be\n",
    "    Z0 = np.full(Y0.shape, np.nan)\n",
    "    Z1 = np.full(Y0.shape >> np.int_(1), np.nan)\n",
    "    Z2 = np.full(Y0.shape >> np.int_(2), np.nan)\n",
    "    Z3 = np.full(Y0.shape >> np.int_(3), np.nan)\n",
    "\n",
    "    return Z3, Z2, Z1, Z0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all is correct, `Z0` should be identical to\n",
    "`X`.  You can check that your function is correct by calculating `np.max(abs(X - Z0))` and also displaying your pyramid of decoded images, `Z3` to `Z0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.25*np.array([1, 2, 1])\n",
    "Z3, Z2, Z1, Z0 = py4dec(Y0, Y1, Y2, Y3, X4, h)\n",
    "encode_decode_err = np.max(np.abs(X - Z0))\n",
    "print(f'Encode-Decode Error = {encode_decode_err}')\n",
    "\n",
    "# your code here to plot the images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further information on the Laplacian Pyramid see Burt and Adelson [IEEE Trans. on Communications, 1983, vol 31, no 4, pp 532-540, \"The Laplacian Pyramid as a compact image code\"]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Quantisation and Coding Efficiency\n",
    "To see whether data compression is possible using the above pyramid decomposition, we must calculate the approximate number of bits required to code the image pyramid. This may be done using the *entropy* of the quantised image data. \n",
    "\n",
    "The entropy of a single data sample, whcih may randomly take one of $Q$ possible quantised values such that each value $q(i)$ has a probability $p(i)$ of being in state $i$ for $i=1\\to Q$ is given by:\n",
    "\n",
    "$$ \\text{Entropy (bits/sample)} = \\sum_{i=1}^Qp(i) \\log_2\\frac{1}{p(i)} = -\\sum_{i=1}^Q p(i) \\log_2p(i)$$\n",
    "\n",
    "The entropy represents the minimum average number of bits per sample needed to code samples with the given probability distribution $p(i)$, assuming that an ideal variable-length entropy code is used, and that the samples are uncorrelated with each other. Arithmetic codes can get arbitrarily close to this bit rate, and simpler Huffman codes can also get vary close with many typical signals (you will be using Huffman codes later on). It is possible to code signals at bit rates less than the entropy, if the samples are correlated, but for simplicity we shall ignore this here.\n",
    "\n",
    "To demonstrate the validity of the above formula, first consider a signal with 8 quantised values of equal probability $p(i) = 1/8$ for all $i$. The entropy is then $8 \\times 1/8 \\times \\log_2(8) = 3$ bits per sample, as expected. \n",
    "\n",
    "Now consider a signal with only 3 values, with probabilities $p(1)=1/2$,  $p(2) = p(3) = 1/4$. The entropy is then $\\frac{1}{2} \\log_2(2) + 2 \\times \\frac{1}{4} \\log_2(4) = 1.5$ bits per sample. This is consistent with using a single bit '0' to represent state 1 and two bits, '10' and '11' to represent states 2 and 3.\n",
    "\n",
    "The function `bpp` has been written to calculate the entropy in bits per pixel of an image matrix `X`. First the function computes a histogram of `X` to determine the probabilities $p(i)$ and then it calculates the entropy, using the above formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import bpp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Laplacian Pyramid, the total number of bits is obtained by multiplying each of the sub-image entropies by the number of pixels in each corresponding sub-image. However, in order to compress the data, we also need to quantise the images. We have also provided a function `quantise` which will quantise `X` in steps centred on integer multiples of `step`. Hence `bpp(quantise(X, step))` will return the entropy of image `X` quantised in steps of `step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cued_sf2_lab.laplacian_pyramid import quantise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Calculate the entropies of images `X` `X1` `Y0` and hence the total numbers of bits to encode `X`, or `X1` and `Y0`, when quantised to a step size of 17 (which gives 15 distict grey levels if applied to a lowpass image with intensities from -127 to 127. Find the data compression for this simple one-stage pyramid, and then investigate the improvements from using more layers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code to calculate compression ratios here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since compressing an image will generally result in a reduction in quality, we also need a way to measure this quality reduction. It is actually quite hard to find a quality measure whcih matches individual perceptions of how an image has been changed due to compression, and for that reason it is important to always judge and comment on an image visually. However we also need a quantitative measure, and the most obvious is the rms error (standard deviation) between the input and compressed image (i.e. using ```np.std(X - Z)``` where `Z` is the compressed image).\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Quantise the Laplacian pyramid with a step size of 17, and reconstruct the output image from the decoding pyramid. Look at the visual features, and calculate the rms error (standard deviation) between the input image and the decoding pyramid output image. Repeat this for more layers in the pyramid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code to explore rms error with the laplacian pyramid here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we call this error the rms error, but in fact we calculate the standard deviation, which only equals the true rms error if the mean error is zero. However the eye is very insensitive to small errors in the mean level of images, so the standard deviation (which ignores the mean) is a better measure of image quality. \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Quantise the original image with the same step size (17) and note the visual features and rms error. Compare these results from the pyramid scheme above. Why are the rms errors larger in the pyramid scheme? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code to calculate the error from directly quantising the original\n",
    "# image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons of the number of bits with different coding strategies are only valid if they result in approximately the same image quantisation error. Write a function which will optimise the step size (resulting in a non-integer value) in the Laplacian scheme until the rms error is the same as for direct quantisation; you will find this optimisation useful for later investigations too.\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Investigate what step size of the quantisers for the pyramid scheme you need, in order to get approximately the same error as for direct quantisation at a step size of 17.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your optimisation and step size selection here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many of your results from now on you will need to expres the performance of your algorithms in terms of *compression ratio*, which is normally defined as:\n",
    "\n",
    "$$ \\text{Compression Ratio} = \\frac{\\text{Total bits for reference scheme}}{\\text{Total bits for compressed scheme}} $$\n",
    "\n",
    "Usually the *reference* scheme is the direct pixel quantisation method with its quantiser adjusted to give the same rms error as the scheme being evaluated (the *compressed* scheme). For good schemes we try to make the compression ratio as large as possible.\n",
    "\n",
    "We now investigate the effect of using different step sizes for the different levels of the pyramid. There are many schemes for varying the step sizes between different levels: in this project we shall look at the *equal MSE* criterion. In the *equal MSE* scheme, step sizes are chosen such that quantisers in each layer contribute equally to the Mean Squared Error of the reconstructed image. In general the step sizes will depend on the image signal being coded. However this can be achieved approximately by choosing a separate step size for each layer such that:\n",
    "* A single impulse of that step size will give a filtered pulse in the reconstructed image which has the same energy, whichever layer of the decoder the impulse excites."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulse Response Measurement\n",
    "Investigate the effect of a single impulse in a particular layer (e.g. **Y0,Y1** etc.) as it appears in the reconstructed image **Z0**. This can be done by first generating a test pyramid image, which is zero everywhere. Then place an impulse (e.g. of amplitude 100) in the centre of one layer, reconstruct the entire pyramid to give **Z0**, then measure the total energy of **Z0**. If this is repeated for each layer, you will have measured how much energy a fixed size impulse at each layer contributes to the decoded image.\n",
    "\n",
    "We actually want to arrange for the impulse sizes to vary and the energy to stay the same. Therefore the impulse sizes (and hence chosen quantisation steps) we require in each level will be inversely proportional to the square root of the energies measured above. The important result is the *ratio* of the step sizes between layers. If this ratio is maintained for any overall quantiser scaling, we will get an (approximately) *equal MSE* scheme."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Find new values for the data compression achievable when all schemes (i.e. constant step size or equal MSE, both with varying layer depth) produce the same rms error between the decoded image and the original image. Comment on the differences in compression, visual quality and rms error, and the optimum choice of layer depth in each case.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the compression ratios for constant step sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the step size ratios for equal MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the quantisation step size for equal mse, matching the reference RMS error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the compression ratios for equal mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Changing the decimation / interpolation filter\n",
    "It is also worth investigating whether a more complicated decimation / interpolation filter **h** can improve the compression. The z-transfer function of the filter used so far is\n",
    "\n",
    "$$ h(z) = \\left(\\frac{1 + z^{-1}}{2}\\right)^m $$\n",
    "\n",
    "where $m = 2$. If $m$ is increased to 4(so the number of taps remains odd), the vector representation of **h** is \\[1/16 4/16 6/16 4/16 1/16\\]. This filter has a lower cut-off frequency than when $m=2$, so you should find that each interpolated lowpass image in the pyramid is a little more blurred, and there is a little more energy left in each highpass image.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Optimise the step sizes for the pyramid with this new filter and determine the new compression performance and visual features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the previous experiments with a new h here\n",
    "h = np.array([1, 4, 6, 4, 1]) / 16.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Interim Report\n",
    "Discuss and explain your results, gathered so far, in your first interim report. Try to answer the questions posed in the above test. Be brief where things are straightforward, but pay more attention to detail in areas where you think something interesting is happening. Write this as a standalone report, not as a series of bullet points answering the questions posed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
